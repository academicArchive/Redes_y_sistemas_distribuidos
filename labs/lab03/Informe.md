---
title: "Analﾃｭsis de flujo y congestiﾃｳn en redes utilizando simulaciﾃｳn discreta "
author:
  - "Guerrero Diego"
  - "Gonzalez Juan Pablo"
  - "Madero Ismael"
  - "Pellegrino Milena"
date: "2025-05-10"
subject: "redes"
subtitle: "Laboratorio 3 - Redes y Sistemas Distribuidos"
lang: "es"
titlepage: true
titlepage-color: "108062"
titlepage-text-color: "FFFAFA"
titlepage-rule-color: "FFFAFA"
titlepage-rule-height: 2
book: true
classoption: oneside
code-block-font-size: \scriptsize
---

# Analﾃｭsis de flujo y congestiﾃｳn en redes utilizando simulaciﾃｳn discreta 

## Resumen
Descirbe lo que se va a encontrar nuestro lector, si lee nuestro trabajo. 
Prestenar el problema a trabajar, de que manera la trabajamos, pequena idea de solucion y describir un poco la estrcutura. 


El visual de bitbucket para MarkDown, no es el mejor, recomendamos verlo en otro lugar. 
Lo que se recomienda es utilizar pandoc y pasarlo a pdf, ya que escribimos un titulo que sin un convertidor como latex o pandoc no se puede observar, para hacerlo hay que descargarlo nuestro archivo .m (junto con la carpeta de las imagenes),y ejecutar: `pandoc Informe.md -o informe.pdf --pdf-engine=xelatex` por comodidad tambien lo dejamos en el repositorio. 

## Integrantes
  - Guerrero Diego
  - Gonzalez Juan Pablo
  - Madero Ismael
  - Pellegrino Milena

## ﾃ肱dice 

1. [Introducciﾃｳn](#introducciﾃｳn)
2. [Experimento 1](#experimento-1)
   - [Caso de estudio 1](#caso-de-estudio-1)
   - [Caso de estudio 2](#caso-de-estudio-2)
   - [Anﾃ｡lisis](#anﾃ｡lisis)
   - [Preguntas](#preguntas)
3. [Experimento 2](#experimento-2)
   - [Algoritmo implementado](#algoritmo-implementado)
   - [Caso de estudio 1](#caso-de-estudio-1-1)
   - [Caso de estudio 2](#caso-de-estudio-2-1)
   - [Preguntas](#preguntas-1)

4. [Conclusiones](#conclusiones)
5. [Referencias](#referencias)
6. [Anexo](#anexo)



## Introducciﾃｳn

En este laboratorio nos centramos en la capa de transporte, con el objetivo de analizar el trﾃ｡fico de red bajo tasas de datos acotadas y tamaﾃｱo de buffers limitados, ademas de diseﾃｱar y proponer diferentes soluciones de control de congestiﾃｳn y flujo. 

Para poder realizar esto usamos Omnet++, una bibloteca con un marco de simulaciﾃｳn en C++ destinado principalmente a la creaciﾃｳn de simuladores de red, nosotros lo utilizamos para poder generar estos modelos de red que posteriormente analizamos. 

### Esquema de nuestra red

![Esquema de red](img/General_Network.png)

El esquema de red utilizado es bastante simple, que consta de tres elementos principales: 
1. nodeTx: nodo generador, es el que genera los paquetes de datos y los envﾃｭa al siguiente componente (queue). 
2. queue: cola de paquetes, es un buffer donde los paquetes que llegan son almacenados hasta que se envﾃｭa al nodo receptor. Sirve para, por ejemplo, si hay congestiﾃｳn, los paquetes se puedan quedar esperando en un lugar, sin que se pierdan. 
3. nodeRx: sink, el nodo receptor, es el encargado de recibir los datos que fueron enviados desde el nodo generador, los recibe una vez que fueron pasados por la queue.

Ademﾃ｡s cabe aclarar que internamente cada nodo cuenta con buffer (ver imﾃ｡genes de abajo) con el objetivo de simular un poco mejor el comportamiento de un red **real**, por ejemplo para simular un retardo realista antes de que el paquete sea transmitido. 

|  |  |
|----------|----------|
| ![](img/General_NodeRx.png) | ![](img/General_NodeTx.png) |

### Flujo y congestiﾃｳn 
Como dijimos anteriormente en la parte de [Introducciﾃｳn](#introducciﾃｳn) queremos diseﾃｱar y proponer soluciones de control de congestiﾃｳn y de control de flujo; para esto damos una explicaciﾃｳn breve de ambos conceptos para que se pueda entender uno de los objetivos del trabajo:

- **Control de flujo:** Es un mecanismo que regula la velocidad de transmisiﾃｳn de datos entre un emisor y un receptor para evitar sobrecargar los dispositivos y asegurar una comunicaciﾃｳn eficiente. EL objetivo es evitar que el emisor envﾃｭe mﾃ｡s datos de los que el receptor puede procesar, ya que esto podrﾃｭa causar pﾃｩrdida de informaciﾃｳn. Para evitar que suceda esto se utilizan algoritmos (vistos en el teﾃｳrico) que ajustan la velocidad de transmisiﾃｳn segﾃｺn la capacidad del receptor. 

- **Control de congestiﾃｳn:** Es una sobrecarga de la red. Ocurre cuando la cantidad de datos que circulan por la red supera la capacidad de la red, lo que provoca retrasos o peor aﾃｺn la pﾃｩrdida de paquetes. Esto se suele solucionar con tﾃｩcnicas como el control de trﾃ｡fico (que lo que hacen en esencia es limitar la cantidad de datos emitidos) o alguna optimizaciﾃｳn de enrutamiento. 

### Simulaciﾃｳn discreta
Para los anﾃ｡lisis de los experimentos (tanto del experimento 1, como del experimento 2) realizamos simulaciones discretas, es decir, los eventos ocurren en momentos especﾃｭficos y el tiempo ocurre en pasos discretos, nosotros utilizamos Omnet++. Hacerlo de esta manera nos permite evaluar el desempeﾃｱo de una red sin la necesidad de tenerla fﾃｭsicamente.


# Experimento 1

Primeramente recordemos los parﾃ｡metros de nuestra red, para este experimento:
Recordemos que en el archivo .ini se encuentran estos parﾃ｡metros, obviamente se pueden modificar, pero los experimentos los fijamos con los siguientes: 

- Tamaﾃｱo de los paquetes: 12500 bytes 
- Tamaﾃｱo de los buffers: 
   - nodeRx: 200
   - nodeTx: 2000000 
   - queue (buffer del medio): 200
- Intervalo de generaciﾃｳn: exponential(0.001), es decir, se elige un numero de la distribuciﾃｳn exponencial con media 0.001 

- Desde el nodeTx hacia el nodo intermedio: 
   - Velocidad de tasa de datos: 1Mbps
   - Delay: 100us

Luego tenemos los parametros de el datarate y los delay de los demas nodos, que son lo que cambia en nuestros casos de estudios. (ambos datos se especifican en la parte de los casos de estudio.)

El objetivo de este experimento es poder analizar el comportamiento de la red al variar el intervalo de generaciﾃｳn (entre 0.1s y 1.0s) esto es comﾃｺn en ambos experimentos. Lo que nosotros observamos para poder hacer el analﾃｭsis es: 
1. El uso de las tres queue 
2. Relaciﾃｳn entre carga transmitida y carga recibida (paquetes/segundo).
3. En el caso de que haya pﾃｩrdidas, medirlas y analizarlas, a travﾃｩs de grﾃ｡ficos. 

## Caso de estudio 1

Primeramente recordemos la tasa de datos para este caso de estudio: 
- `queue.out --> { datarate = 0.5Mbps; } --> sink.in;` es decir, nuestra tasa de datos, desde el nodo intermedio hacia el sink es de 0.5Mbps
- `queue.out --> { datarate = 0.5Mbps; } --> nodeRx.in;` 

## Caso de estudio 2
Primeramente recordemos la tasa de datos para este caso de estudio:
- `queue.out --> { datarate = 1Mbps; } --> sink.in;` es decir, nuestra tasa de datos es de 1Mbps, el doble que el caso de estudio 1. 
- `queue.out --> { datarate = 0.5Mbps; delay = 100us; } --> nodeRx.in;`, es decir, es la misma tasa de datos (0.5 Mbps) del caso de estudio 1, pero ahora se agrega un retardo de 100 ﾂｵs en la transmisiﾃｳn hacia NodeRx


## Analisﾃｭs
Para poder analizar este caso de estudio, se hicieron diferentes graficas, a partir de los datos extraidos en las simulaciones con los parametros establecidos anteriormente; ademﾃ｡s para cada caso se tomaron las medidas con intervalos de generaciﾃｳn de: 0.1, 0.15, 0.25, 0.39 y 1. 

### Tamaﾃｱo de buffers
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/(0.1)/buffers.png) | ![](img/CASO_ESTUDIO_1/(0.15)/buffers.png) | ![](img/CASO_ESTUDIO_1/(0.25)/buffers.png) | ![](img/CASO_ESTUDIO_1/(0.39)/buffers.png) | ![](img/CASO_ESTUDIO_1/(1)/buffers.png) |
| 2 | ![](img/CASO_ESTUDIO_2/(0.1)/buffers.png) | ![](img/CASO_ESTUDIO_2/(0.15)/buffers.png) | ![](img/CASO_ESTUDIO_2/(0.25)/buffers.png) | ![](img/CASO_ESTUDIO_2/(0.39)/buffers.png) | ![](img/CASO_ESTUDIO_2/(1)/buffers.png) |

### Carga ﾃｺtil vs carga ofrecida 
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/(0.1)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_1/(0.15)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_1/(0.25)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_1/(0.39)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_1/(1)/ﾃｺtil_vs_ofrecida.png) |
| 2 | ![](img/CASO_ESTUDIO_2/(0.1)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_2/(0.15)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_2/(0.25)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_2/(0.39)/ﾃｺtil_vs_ofrecida.png) | ![](img/CASO_ESTUDIO_2/(1)/ﾃｺtil_vs_ofrecida.png) |

| Caso |  |
|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/ﾃｺtil_vs_ofrecida_1.png) | 
| 2 | ![](img/CASO_ESTUDIO_2/ﾃｺtil_vs_ofrecida_2.png) |

### Pﾃｩrdida de paquetes en queue
En este grﾃ｡fica analizamos la relaciﾃｳn entre el tamaﾃｱo del buffer de la cola y los descartes
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/(0.1)/pﾃｩrdida_con_queue.png) | ![](img/CASO_ESTUDIO_1/(0.15)/pﾃｩrdida_con_queue.png) |  |  |  |
| 2 | ![](img/CASO_ESTUDIO_2/(0.1)/pﾃｩrdida_con_queue.png) | ![](img/CASO_ESTUDIO_2/(0.15)/pﾃｩrdida_con_queue.png) |  |  |  |

### Pﾃｩrdida de paquetes 
En este grﾃ｡fica analizamos la cantidad de pﾃｩrdida de paquetes a travﾃｩs del tiempo.
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/(0.1)/pﾃｩrdida_de_paquetes.png) | ![](img/CASO_ESTUDIO_1/(0.15)/pﾃｩrdida_de_paquetes.png) |  |  |  |
| 2 | ![](img/CASO_ESTUDIO_2/(0.1)/pﾃｩrdida_de_paquetes.png) | ![](img/CASO_ESTUDIO_2/(0.15)/pﾃｩrdida_de_paquetes.png) |  |  |  |

### Pﾃｩrdida de paquetes 
En este grﾃ｡fica analizamos la relaciﾃｳn acumulativa entre los paquetes utilizados contra los paquetes generados
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/CASO_ESTUDIO_1/(0.1)/relaciﾃｳn_paquetes_gen_vs_used.png) | ![](img/CASO_ESTUDIO_1/(0.15)/relaciﾃｳn_paquetes_gen_vs_used.png) |  |  |  |
| 2 | ![](img/CASO_ESTUDIO_2/(0.1)/relaciﾃｳn_paquetes_gen_vs_used.png) | ![](img/CASO_ESTUDIO_2/(0.15)/relaciﾃｳn_paquetes_gen_vs_used.png) |  |  |  |


## Preguntas

**ﾂｿQuﾃｩ diferencia observa entre el caso de estudio 1 y 2? ﾂｿCuﾃ｡l es la fuente limitante en cada uno? Investigue sobre la diferencia entre control de flujo y control de congestiﾃｳn (ver Figura 6-22 del libro Tanenbaum).**

Despuﾃｩs de hacer las mediciones y analizar cada caso, podemos ver que no hay mucha diferencia entre el caso 1 y el caso 2; esto es algo que podiamos intuir ya que en ambos casos nuestro sistema de red que se usa es practicamentela misma, con un cambio minimo en el cuello de botella. 

Luego observando la grﾃ｡fica de tamaﾃｱo de buffer, junto con los de pﾃｩrdidas de paquetes, podemos encontrar una relaciﾃｳn que cuando el buffer se llena se empiezan a perder paquetes, esto ocurre asﾃｭ porque la red no le queda otro camino, tiene los buffers llenos y no tiene otro camino para mandar los paquetes, entonces no le queda otra opciﾃｳn que descartarlos. 

Tambiﾃｩn obersamos que la perdida de paquetes a lo largo del tiempo tiene una forma lineal, en el caso del intervalo de generaciﾃｳn 0.1 y mﾃ｡s o menos lineal en los demﾃ｡s, esto ocurre porque nuestra simulaciﾃｳn es sin eventos fluctuantes, cuando se llena el buffer, se empiezan a perder los paquetes linealmente. 

Luego viendo los diferentes cambios entre los intervalo de generaciﾃｳn que nosotros elegimos para el analisis, podemos ver como  "mejoran" (con mejorar nos referimos a que tienen menos paquetes pﾃｩrdidos y menor delay entre los envﾃｭos.) En las grﾃ｡ficas observamos que a partir del 0.25 se dejaban de perder significativamente paquetes. 

(la pregunta de la diferencia entre control de flujo y control de congestiﾃｳn fue respondida en la parte introductorio del informe.)

En resumen, lo que queriamos estudiar es la perdida de paquetes, que como dijimos anteriormente se puede dar por problema de flujo o problema de congestiﾃｳn. En nuestro caso de estudio 1, si observamos el nodeRx, como si fuera el receptor de la transferencai de paquetes, la pﾃｩrdida ocurre en esa instancia, por lo que lo catalogarﾃｭamos como un problema de flujo; en cambio, en nuestro caso de estudio 2, nuestra queue del medio tiene una tasa de transferencia mﾃ｡s chica en el out que en el in, por lo tanto el gate in causa una pﾃｩrdida de paquetes un poco antes de entrar al nodeRx, aunque esta diferencia es muy sutil. 

# Experimento 2

Nuestro siguiente objetivo, fue diseﾃｱar un sistema de control de flujo y congestiﾃｳn de tal manera que se pueda evitar la pﾃｩrida de datos por saturaciﾃｳn de los buffers, algo que vimos que ocurre en nuestro experimento anterior. 

Primeramente se modifico un poco el sistema de red. Ahora estﾃ｡ formada de la siguiente manera:

|  |  |
|----|----|
| ![](img/General_Network_Diseno.png) | **Nuestra red principal:**<br><br>- **nodeTx**: Nodo transmisor que conecta hacia dos colas:<br>  - Envﾃｭa paquetes a `queue` (red principal)<br>  - Recibe desde `trqueue`<br><br>- **queue**: Cola intermedia entre nodeTx y nodeRx:<br>  - Simula la red principal <br><br>- **trqueue**: Cola paralela para control de trafico:<br>  - La necesitamos para enviar paquetes entre `nodeRx` y `nodeTx` <br><br>- **nodeRx**: Nodo receptor:<br>  - gracias a la `trqueue` puede "vovler hacia atras" | | 
| ![](img/General_NodeRx_Diseno.png) | **Nodo receptor:**<br><br>- **traRx**: Cola de recepciﾃｳn, donde se van almacenando los paquetes que entran. <br><br>- **sink**: Destino final de esos paquetes, como si fuera el recolector de los paquetes entrantes. | | 
| ![](img/General_NodeTx_Diseno.png) | **Nodo transmisor:**<br><br>- **traRx**: Cola de recepciﾃｳn, donde se van almacenando los paquetes que entran. <br><br>- **gen**: Generador de paquetes, crea los paquetes que se enviarﾃ｡n. | | 



## Algoritmo implementado 
Nuestro algoritmo lo que hace es que el transportRx guarda en una cola los ultimos delaySize(.ini) delays y los va promediando.
Lo que hacemos es agarrar el delay actual y calcular la diferencia de porcentaje entre el delay contra el promedio de delays si este porcentaje es mayor al modulo de un errPercent(.ini), si se da entonces envia un mensaje de solicitud de modificaciﾃｳn de serviceTime del nodo transportTx.
transportTx esta programado para ignorar una cantidad ignore (.ini) de paquetes luego de recibir uno, esto porque hasta que se actualice la cola de delays va a tardar lo suyo.


## Caso de estudio 1 y caso de estudio 2 

Obviamente los casos de estudio son utilizando los mismo parametros que en el los casos de estudios anteriores. 

Observemos y analizemos las simulaciones: 

### Tamaﾃｱo de buffers
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.1)/buffers.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.15)/buffers.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.25)/buffers.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.39)/buffers.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(1)/buffers.png) |
| 2 | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.1)/buffers.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.15)/buffers.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.25)/buffers.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.39)/buffers.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(1)/buffers.png) |



### Carga ﾃｺtil vs carga ofrecida
En este grﾃ｡fica analizamos la cantidad de pﾃｩrdida de paquetes
| Caso | 0.1 | 0.15 | 0.25 | 0.39 | 1   |
|----|----|----|----|----|----|
| 1 | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.1)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.15)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.25)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(0.39)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/(1)/ﾃｺtil_vs_ofrecida.png) |
| 2 | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.1)/ﾃｺtil_vs_ofrecido.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.15)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.25)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(0.39)/ﾃｺtil_vs_ofrecida.png) | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/(1)/ﾃｺtil_vs_ofrecida.png) |

| Caso |  |
|----|----|
| 1 | ![](img/DISEﾃ前/CASO_1_(DISEﾃ前)/ﾃｺtil_vs_ofrecida.png) | 
| 2 | ![](img/DISEﾃ前/CASO_2_(DISEﾃ前)/ﾃｺtil_vs_ofrecida.png) |

## Preguntas

**ﾂｿCﾃｳmo cree que se comporta su algoritmo de control de flujo y congestiﾃｳn4? ﾂｿFunciona
para el caso de estudio 1 y 2 por igual? ﾂｿPor quﾃｩ?**

Nuestro acf analiza los delays de los paquetes llevando un promedio de los ultimos n paquetes, de esta manera puede determinar si el ﾃｺltimo paquete recibido demoro notablemente mas o menos que el promedio de los anteriores n paquetes:
Si es el caso entonces se envﾃｭa al transportTx un porcentaje de aumento o decremento de serviceTime mediante un paquete.
Cuando transportTx recibe dicho paquete puede ignorarlo (si recientemente acepto uno de estos paquetes) o aceptarlo.
Si lo acepta entonces suma el porcentaje solicitado a un campo de su clase llamado timeModifier el cual luego se multiplica por el serviceTime.
De esta manera modificando la cadencia de paquetes enviados.

Utilizando las mismas justificaciones del experimento 1 y analizando las graficas, no se encuentran grandes diferencias entre el caso de estudio 1 y el caso de estudio 2.

Cabe aclarar que en nuestra simulaciﾃｳn no se modelﾃｳ la caﾃｭda de red, por lo que los paquetes que no llegaron al nodo receptor al finalizar la simulaciﾃｳn no se consideran pﾃｩrdidos, sino simplemente no se contabilizan por haber quedado en transito, pero no fueron dropeados, ya que nunca se llego a llenar el buffer, esto es asﾃｭ ya que nuestra simulaciﾃｳn tiene un tiempo limitado, por este motivo se ven asﾃｭ las graficas. 

## Conclusiones

Logramos hacer un acf para poder solucionar el problema de control de flujo y control de congestiﾃｳn, aunque no es perfecto y hay varios aspectos que se pueden mejorar, por ejemplo viendo cuales seria los parametros ideales para diferentes tipos de red, o modificarlo para que no haya tanto delay entre paquetes, ademas de tratar de llevar al maximo la capacidad de la red, en la que nosotros hicimos las simulaciones y realizamos estos algoritmos capaz no se ve tan afectada, pero en redes mas grandes los cambios serian significativos. 

## Referencias

- [Documentaciﾃｳn oficial de Omnet++](https://omnetpp.org/documentation/)
- [Manual de Omnet++](https://doc.omnetpp.org/omnetpp5/manual/)
- [Introducciﾃｳn a Omnet++ y c++ (filminas)](https://drive.google.com/file/d/1xx5pSrQE5PUczFH7eUAPKU23-dclSdeF/view)
- [Introducciﾃｳn a Omnet++ y c++ (video)](https://www.youtube.com/watch?v=hgRW5rK-CDE&t=1616s)
- [Graficas en Omnet++ con Python y Notebooks](https://www.youtube.com/watch?v=yL1gf04E2_E)
- [Curva de Carga Ofrecida vs Carga Util](https://www.youtube.com/watch?v=W8r8zSPjeAs)
- [Graficar en google colab](https://colab.research.google.com/drive/1wOr1jP7-s076qyJl7gxgQ63cqiEYJ8g0?usp=sharing)
- [Estructura de un informe](https://www.youtube.com/watch?v=yq8zjLZABe0)


Cabe aclarar que vimos el video sobre la estructura del informe, pero solo incluimos algunos apartados como abstract, referencias, introducciﾃｳn. Para los otros nos tomamos la libertad de divididir el informe en secciones de exp1 y exp2 y luego un apartado de conclusiones general. (en el video se proponia que en la introducciﾃｳn pongamos el anﾃ｡lisis de los problemas en el caso1 y caso2, en una secciﾃｳn mﾃｩtodo se explique la tarea de diseﾃｱo, etc; nosotros decidimos hacerlo de esta manera ya que nos parecio un poco mas prolijo y mas ordenado a la hora en la que alguien lo tenga que leer; igualmente tenemos en cuenta que esto puede ser subjetivo y podriamos haber seguido la alineaciﾃｳn propuesta por la catedra). 

## Anexo

Creemos pertinente aclarar que al no tener el tiempo deseado para la realizaciﾃｳn del lab, para la ﾃｺltima parte del laboratorio nos organizamos dividiendo las tareas principales, siempre comunicandonos y entendiendo en cada momento lo que hacia el otro compaﾃｱero. @IsmaelMadero se encargo de programar el diseﾃｱo de nuestro algoritmo, @JuanPGonzalez fue el encargado de realizar las simulaciones y realizar las graficas (algo que capaz no se vea en el historial de commits), @MilenaPellegrino, se encargo de realizar el informe y analizar las graficas y @DiegoGuerrero se encargo de debuggear. A su vez hicimos mucho pairprogramming, tanto en las clases presenciales como remotamente.

Hemos utilizado diferentes herramientas de Inteligencia Artificial a lo largo del laboratorio, en diferentes ocasiones y usos. 

1. Primeramente utilizamos [ChatGPT](https://chatgpt.com/) para entender algunas partes del cﾃｳdigo proporcionado por la cﾃ｡tedra, que al leer la documentaciﾃｳn no nos quedaba del todo claro.

   1. 
      - **Prompt**: Podrﾃｭas explicarme quﾃｩ es lo que hace `par("algo")` en OMNeT++.
      - **Respuesta**: *Lo de `par("nombre")` significa que estﾃ｡s accediendo a un parﾃ｡metro del mﾃｳdulo en OMNeT++. `par("nombre")` te da acceso al valor de un parﾃ｡metro definido en el archivo .ned del mﾃｳdulo. Es como una variable configurable desde afuera del cﾃｳdigo C++.*
      - **Verificaciﾃｳn**: Lo verificamos observando el cﾃｳdigo y viendo que lo que se encontraba adentro del parﾃｩntesis efectivamente era un parﾃ｡metro en el archivo `.ned`. Luego de leer la respuesta de ChatGPT, volvﾃｭamos a leer la documentaciﾃｳn con un poco mﾃ｡s de conocimiento para poder entenderlo del todo.

   2. 
      - **Prompt**: ﾂｿPodrﾃｭas explicarme quﾃｩ es lo que hace `exponential(0.001)` en el contexto de OMNeT++?
      - **Respuesta**: *Cuando escribﾃｭs `exponential(0.001)` en OMNeT++, estﾃ｡s diciendo: "Quiero que este valor se genere aleatoriamente siguiendo una distribuciﾃｳn exponencial con media 0.001 segundos (o sea, 1 milisegundo)."*
      - **Verificaciﾃｳn**: En este caso lo preguntamos porque no encontrﾃ｡bamos fﾃ｡cilmente informaciﾃｳn sobre el funcionamiento de `exponential(0.001)`. Encontramos un [manual](https://doc-omnetpp-org.translate.goog/omnetpp/manual/?_x_tr_sl=en&_x_tr_tl=es&_x_tr_hl=es&_x_tr_pto=tc) sobre OMNeT++ pero cuando explicaba lo de `exponential` era bastante vago. Para verificar, probamos quﾃｩ hacﾃｭa y leﾃｭmos el cﾃｳdigo para ver si tenﾃｭa sentido.

   3. 
      - **Prompt**: ﾂｿEstamos hacineod un proyecto en omentpp, segun la documentaciﾃｳn de omentpp esto es lo que hace la funciﾃｳn scheduleAt (insertamos una imﾃ｡gen de la doc) lo que yo entiendo es que scheduleAt es un mensaje para el mismo proceso que lo ejecuta esto es correcto?
      - **Respuesta**: *ﾂ｡Exactamente! 泗 En OMNeT++, scheduleAt(tiempo, mensaje) agenda un evento (mensaje) para que sea entregado al mismo mﾃｳdulo que lo programﾃｳ, en el momento tiempo del reloj de simulaciﾃｳn*
      - **Verificaciﾃｳn**: Acﾃ｡ no verificamos muchos, ya que utilizamos la herramienta para poder ver si lo que habiamos leﾃｭdo sobre [scheduleAt](https://doc.omnetpp.org/omnetpp/apiclassomnetpp_1_1cSimpleModulehtml#a97c57271ca2fc95225ed8514750cac27)  era correcto o estabamos mal encaminados.

2. Utilizaciﾃｳn de [Gemini](https://gemini.google.com/), lo usamos al utilizar [Google Colab](https://colab.google/) muchas veces tenﾃｭamos varios errores al hacer las grﾃ｡ficas, y la explicaciﾃｳn del error que tiraba python o la librerﾃｭa que usabamos era muy vaga y no llegabamos a entenderla, por lo tanto como Colab tiene incorporado Gemini, lo utilizamos para que nos explique mejor estos errores: 
   1. 
      - **Prompt**: Porfavor, podrﾃｭas explicarme este error: [insertabamos el error] ejemplo: `AttributeError: 'float' object has no attribute 'split' `
      - **Respuesta**: *The error message AttributeError: 'float' object has no attribute 'split' indicates that you are trying to apply the split() method to a float object, but this method is only available for strings. This is happening because time_gen, time_queue, time_sink, buffer_gen, buffer_queue, and buffer_sink variables are already lists of floats based on the Global variables provided. The line of code time_gen[0].split() tries to access the first element of time_gen, which is a float, and then apply the split() method to it. Since floats don't have a split() method, this causes an AttributeError.*
      - **Verificaciﾃｳn**: La verificaciﾃｳn era hacer lo que nos decﾃｭa y ver si tenﾃｭa razﾃｳn. Cabe aclarar que para la mayorﾃｭa no era 100% correcto, pero nos tiraba una idea de cual era el problema del error y pensando un poco se solucionaba. 

3. Utilizaciﾃｳn de [Copilot](https://copilot.microsoft.com), lo usamos para escribir el informe, ya que utlizamos chatGPT para tratar de hacer items dentro de tablas, pero al explicarme lo que queriamos chatGPT no entendia, por lo tanto le pasamos la tabla en la que queriamos hacer items alado, pero lo que hizo chatGPT fue reescribir todo lo que nosotro s escribimos, utilizando otros datos y cosas que no eran correcta para nuestro proyecto, por lo tanto decidimos utilizar copilot, el cual no reescribio la respuesta y solo nos explico como hacer, ya que utilizaba html.